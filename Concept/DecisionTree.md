# 의사결정나무(Decision Tree)
- 입력값에 대한 예측값을 나무 형태로 나타내어주는 모형
## 작동 원리
- 재귀적 분기(Recursive Partitioning)
    - 정보 획득(분기 전/후의 불순도 감소량)이 가장 큰 분기점을 찾아 분할하며 정보 획득이 더 이상 없어질 때까지(불순도가 0%인 Full Tree가 될 때까지) 반복
- 가지치기(Pruning)
    - 과적합을 방지하기 위해 테스트 데이터의 에러가 증가하는 부분 근방에서 분기하기
## 장단점
### 장점
- 반드시 특정 축에 수직이므로 설명력을 가짐
- 데이터 전처리(정규화, 이상치 처리) 덜 해도 잘 돌아감
### 단점
- 한 번에 독립변수 하나씩 활용해서 독립변수간 상호작용 고려할 수 없음
- 예측력이 떨어짐(특히, 다수결과 달리 이상치에 영향을 받을 수 있는 평균을 사용하는 회귀나무는 더 안 좋음)

